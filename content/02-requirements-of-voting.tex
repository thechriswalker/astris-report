
\chapter{Requirements of Voting Systems}
\label{ch:req}

\section{Security Requirements}
\label{ch:req:sec}

There have been many papers outlining the security requirements specific to voting \cite{epstein_electronic_2007}, \cite{delaune_formalising_nodate}. Here we outline the important ones.

\todo{Security Requirements for voting systems... Here we start with the citations}

\section{Trust Requirements}
\label{ch:req:trust}

The \gls{oed} defines trust as follows:

\vspace{1em}
\noindent \begin{tabular}{|p{0.9\textwidth}}
    \noindent \textbf{noun}: Firm belief in the reliability, truth, or ability of someone or something.
\end{tabular}
\vspace{1em}

This is a difficult thing to quantify. Romano \cite{romano_nature_2003} defines a scale for measuring trust, but it is very subjective. We want to remove as much subjectivity from the question of trust and move it into something definite that we can answer --- is it \emph{easier} to trust $X$ or $Y$?

Trust can be defined as a binary thing: either you trust something or you don't. Trust can also be considered as a continuous thing: you can trust something a little or a lot. I believe the two concepts are related, in that the amount of continuous trust you have in something must exceed the trust requirements it imposes on you for you to consider that you have the binary trust in it.

Often the thing you have continuous trust in --- to whatever extent --- will only be converted into the binary trust at the point of deciding to rely on that thing. At this point the value of the thing and the impact of the trust being subverted come into play to make the final decision.

With respect to voting systems trust is the belief that the system will work fairly and correctly and that it will be resistant to attempts to subvert it. Whether we trust this is the case or not for any given election is subjective and personal, however knowledge that the system is designed in a way to resist subversion attempts will greatly reduce the amount of trust we must extend to the system in order to have that belief.

Let us take a simple example, based on a well known trust exercise. You stand on a chair and there are $N$ people behind you. You fall back trusting that they will catch you and let us say that if any one person reaches to catch you then you will be safe. Clearly, if you know the people behind you, you will be better placed to make a judgement on each one's individual likelihood of letting you fall. Assuming you have no prior knowledge of the individuals behind you cannot make such a judgement. We do know $N$ and the greater the value of $N$ --- the number of people behind you --- the more likely it is that one of them will act in good faith. We can make our own judgement on the probability of a single person being a bad actor and call it $P_b$ then the probability of all actors being bad --- our failure condition --- will be $(P_b)^N$. For any value of $P_b < 1$ then $(P_b)^N$ becomes small very quickly as $N$ rises.

As we increase the $N$ value of the system of this exercise, we lower the trust requirements. We could make a reasonable assumption that in most cases the individuals will likely not have motivation to subvert the exercise --- people generally have enough empathy and would not want to see you fall --- therefore we would estimate our $P_b$ to be low and so even with only a few people we could easily exceed the trust requirements placed on us and fall back confidently.


\todo{ Now look at the requirements previously stated and discuss trust}